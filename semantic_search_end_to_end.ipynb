{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#cloud-id=\"be3462376d494497ac6a0785c37e27b5\"\n",
        "#colab-key=\"aC1ZcGZKZ0JMbE9ZUkY5a0RkaTc6Q1gtSTVVMTQ4N0xDTGRlRUk4TXFBQQ==\""
      ],
      "metadata": {
        "id": "fXlL9iO4_NMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"⏳ Step 1: Performing a clean installation of all dependencies...\")\n",
        "\n",
        "# First, uninstall any existing conflicting versions to ensure a clean state\n",
        "!pip uninstall -y sentence-transformers transformers huggingface-hub\n",
        "\n",
        "# Now, install the latest stable versions which are compatible with each other\n",
        "!pip install -q \"sentence-transformers\" \"transformers\" \"huggingface-hub\"\n",
        "!pip install -q flask pyngrok elasticsearch==7.17.9\n",
        "\n",
        "print(\"✅ Dependencies installed cleanly.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oh6mdUFcPMlI",
        "outputId": "ab2b2531-0d04-4441-e1c5-0e28b19fef8e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏳ Step 1: Performing a clean installation of all dependencies...\n",
            "Found existing installation: sentence-transformers 2.7.0\n",
            "Uninstalling sentence-transformers-2.7.0:\n",
            "  Successfully uninstalled sentence-transformers-2.7.0\n",
            "Found existing installation: transformers 4.31.0\n",
            "Uninstalling transformers-4.31.0:\n",
            "  Successfully uninstalled transformers-4.31.0\n",
            "Found existing installation: huggingface-hub 0.23.0\n",
            "Uninstalling huggingface-hub-0.23.0:\n",
            "  Successfully uninstalled huggingface-hub-0.23.0\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m470.2/470.2 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m101.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m558.8/558.8 kB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h✅ Dependencies installed cleanly.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pyngrok import ngrok\n",
        "from elasticsearch import Elasticsearch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "\n",
        "print(\"⏳ Step 2: Connecting to services...\")\n",
        "\n",
        "# ❗️ PASTE YOUR CREDENTIALS HERE\n",
        "ENDPOINT_URL = \"https://my-elasticsearch-project-be3462.es.asia-south1.gcp.elastic.cloud:443\"\n",
        "API_KEY = \"aC1ZcGZKZ0JMbE9ZUkY5a0RkaTc6Q1gtSTVVMTQ4N0xDTGRlRUk4TXFBQQ==\"\n",
        "NGROK_AUTHTOKEN = \"30M4sFq07MnnJN7ao11As3FeOoo_64mq5pD6GSnPzk62CY2N\"\n",
        "\n",
        "\n",
        "# --- Configure ngrok ---\n",
        "os.system(f\"ngrok config add-authtoken {NGROK_AUTHTOKEN}\")\n",
        "\n",
        "\n",
        "# --- Connect to your Elastic Cloud deployment ---\n",
        "try:\n",
        "    # Use the Endpoint URL and API Key to connect\n",
        "    es_client = Elasticsearch(\n",
        "        hosts=[ENDPOINT_URL],\n",
        "        api_key=API_KEY\n",
        "    )\n",
        "    # Test the connection by getting cluster info\n",
        "    es_client.info()\n",
        "    print(\"✅ Successfully connected to Elastic Cloud.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error connecting to Elastic Cloud: {e}\")\n",
        "    print(\"Please double-check your Endpoint URL and API Key.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v63wGqYGPhMs",
        "outputId": "14fada6d-dd56-49f7-a3e0-528c46ce44ed"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏳ Step 2: Connecting to services...\n",
            "✅ Successfully connected to Elastic Cloud.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "\n",
        "print(\"\\n⏳ Step 3: Loading NLP model and indexing data...\")\n",
        "\n",
        "# Load tokenizer and model from Hugging Face Hub\n",
        "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-mpnet-base-v2')\n",
        "model = AutoModel.from_pretrained('sentence-transformers/all-mpnet-base-v2')\n",
        "\n",
        "# Define the mean pooling function to create a single sentence embedding\n",
        "def mean_pooling(model_output, attention_mask):\n",
        "    token_embeddings = model_output[0]\n",
        "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
        "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
        "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
        "    return sum_embeddings / sum_mask\n",
        "\n",
        "# Define the main function to convert text to a vector\n",
        "def encode(text):\n",
        "    encoded_input = tokenizer(text, padding=True, truncation=True, return_tensors='pt')\n",
        "    with torch.no_grad():\n",
        "        model_output = model(**encoded_input)\n",
        "    sentence_embedding = mean_pooling(model_output, encoded_input['attention_mask'])\n",
        "    return sentence_embedding.tolist()[0]\n",
        "\n",
        "print(\"✅ NLP model loaded.\")\n",
        "print(\"   - Indexing data into Elasticsearch...\")\n",
        "\n",
        "# Sample Q&A data\n",
        "documents = [\n",
        "    {\"question\": \"What is the capital of France?\", \"answer\": \"The capital of France is Paris.\"},\n",
        "    {\"question\": \"How does a car engine work?\", \"answer\": \"An engine converts fuel into mechanical energy through combustion.\"},\n",
        "    {\"question\": \"What is solar power?\", \"answer\": \"Solar power is energy from the sun that is converted into thermal or electrical energy.\"},\n",
        "    {\"question\": \"Who wrote 'Hamlet'?\", \"answer\": \"'Hamlet' was written by William Shakespeare.\"},\n",
        "    {\"question\": \"How can I fix my vehicle?\", \"answer\": \"Automobile repair depends on the specific issue, from changing a tire to servicing the engine.\"}\n",
        "]\n",
        "\n",
        "index_name = \"qa_index\"\n",
        "index_mapping = {\n",
        "    \"properties\": {\n",
        "        \"question_vector\": {\"type\": \"dense_vector\", \"dims\": 768},\n",
        "        \"question\": {\"type\": \"text\"},\n",
        "        \"answer\": {\"type\": \"text\"}\n",
        "    }\n",
        "}\n",
        "\n",
        "# Create the index\n",
        "if es_client.indices.exists(index=index_name):\n",
        "    es_client.indices.delete(index=index_name)\n",
        "es_client.indices.create(index=index_name, mappings=index_mapping)\n",
        "\n",
        "# Index each document\n",
        "for doc in documents:\n",
        "    question_vector = encode(doc[\"question\"])\n",
        "    es_client.index(index=index_name, body={\n",
        "        \"question\": doc[\"question\"],\n",
        "        \"answer\": doc[\"answer\"],\n",
        "        \"question_vector\": question_vector\n",
        "    })\n",
        "\n",
        "print(\"✅ Data indexed successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBBFU3_LQAMr",
        "outputId": "0ff15439-a747-4f3e-b853-1d0a76a8667c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "⏳ Step 3: Loading NLP model and indexing data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ NLP model loaded.\n",
            "   - Indexing data into Elasticsearch...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4103301253.py:55: DeprecationWarning: The 'body' parameter is deprecated for the 'index' API and will be removed in a future version. Instead use the 'document' parameter. See https://github.com/elastic/elasticsearch-py/issues/1698 for more information\n",
            "  es_client.index(index=index_name, body={\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Data indexed successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, render_template_string\n",
        "from pyngrok import ngrok\n",
        "\n",
        "print(\"\\n⏳ Step 4: Creating and starting the Flask web application...\")\n",
        "app = Flask(__name__)\n",
        "\n",
        "# --- Search Function ---\n",
        "def search_semantic(query):\n",
        "    query_vector = encode(query)\n",
        "    search_query = {\n",
        "        \"script_score\": {\n",
        "            \"query\": {\"match_all\": {}},\n",
        "            \"script\": { \"source\": \"cosineSimilarity(params.query_vector, 'question_vector') + 1.0\", \"params\": {\"query_vector\": query_vector} }\n",
        "        }\n",
        "    }\n",
        "    response = es_client.search(index=index_name, query=search_query)\n",
        "    results = [{\"score\": hit[\"_score\"], \"question\": hit[\"_source\"][\"question\"], \"answer\": hit[\"_source\"][\"answer\"]} for hit in response[\"hits\"][\"hits\"]]\n",
        "    return results\n",
        "\n",
        "# --- HTML Template ---\n",
        "HTML_TEMPLATE = \"\"\"\n",
        "<!DOCTYPE html><html lang=\"en\"><head><title>Semantic Q&A Search</title>\n",
        "<style>\n",
        "    body { font-family: -apple-system, BlinkMacSystemFont, \"Segoe UI\", Roboto, Helvetica, Arial, sans-serif; margin: 40px; background-color: #f4f4f9; color: #333; }\n",
        "    .container { max-width: 800px; margin: 0 auto; background-color: #fff; padding: 30px; border-radius: 8px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }\n",
        "    h1 { color: #2c3e50; text-align: center; } form { display: flex; margin-bottom: 30px; }\n",
        "    input[type=\"text\"] { flex-grow: 1; padding: 12px; border: 2px solid #ddd; border-radius: 6px 0 0 6px; font-size: 16px; }\n",
        "    input[type=\"submit\"] { padding: 12px 25px; border: none; background-color: #3498db; color: white; border-radius: 0 6px 6px 0; font-size: 16px; font-weight: bold; cursor: pointer; }\n",
        "    .result { border-bottom: 1px solid #eee; padding: 15px 0; } .result:last-child { border-bottom: none; }\n",
        "    .result h3 { margin: 0 0 5px 0; color: #2980b9; } .result p { margin: 0; }\n",
        "    .result .score { font-size: 12px; color: #7f8c8d; font-weight: bold; }\n",
        "</style></head>\n",
        "<body><div class=\"container\">\n",
        "    <h1>Semantic Q&A Search (Cloud Ver.)</h1>\n",
        "    <form method=\"post\"><input type=\"text\" name=\"query\" placeholder=\"Ask a question...\" value=\"{{ query }}\"><input type=\"submit\" value=\"Search\"></form>\n",
        "    {% if results %}{% for result in results %}<div class=\"result\">\n",
        "        <h3>{{ result.question }}</h3><p>{{ result.answer }}</p>\n",
        "        <p class=\"score\">Similarity Score: {{ \"%.4f\"|format(result.score - 1) }}</p>\n",
        "    </div>{% endfor %}{% elif query %}<p class=\"no-results\">No results found.</p>{% endif %}\n",
        "</div></body></html>\n",
        "\"\"\"\n",
        "\n",
        "# --- Main Route ---\n",
        "@app.route('/', methods=['GET', 'POST'])\n",
        "def home():\n",
        "    results = None; query = ''\n",
        "    if request.method == 'POST':\n",
        "        query = request.form.get('query', '')\n",
        "        if query: results = search_semantic(query)\n",
        "    return render_template_string(HTML_TEMPLATE, results=results, query=query)\n",
        "\n",
        "print(\"✅ Flask application created.\")\n",
        "\n",
        "# --- Start ngrok tunnel and run app ---\n",
        "public_url = ngrok.connect(5000)\n",
        "print(f\"\\n\\n🚀🚀🚀 Your App is LIVE! Open this URL in your browser: {public_url} 🚀🚀🚀\")\n",
        "app.run(port=5000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdqdMqVRQNxl",
        "outputId": "f146ef61-1ee8-4c1c-f3bf-160ddf5f6754"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "⏳ Step 4: Creating and starting the Flask web application...\n",
            "✅ Flask application created.\n",
            "\n",
            "\n",
            "🚀🚀🚀 Your App is LIVE! Open this URL in your browser: NgrokTunnel: \"https://e0418bf4d594.ngrok-free.app\" -> \"http://localhost:5000\" 🚀🚀🚀\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug:127.0.0.1 - - [05/Aug/2025 22:17:50] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [05/Aug/2025 22:17:51] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [05/Aug/2025 22:17:57] \"POST / HTTP/1.1\" 200 -\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N4ROLvcbQfcP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}